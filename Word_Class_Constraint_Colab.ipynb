{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-Class Constraint Audit\n",
    "\n",
    "**Better alternative to POS tagging** (works with BPE tokenization)\n",
    "\n",
    "## Research Question\n",
    "Does syntactic structure shift probability mass toward word-initial tokens (vs. fragments/punctuation)?\n",
    "\n",
    "## Prediction\n",
    "After determiners (e.g., \"the\"):\n",
    "- **Sentence/Jabberwocky**: HIGH % word-start (structure intact)\n",
    "- **Scrambled**: LOWER % word-start (structure disrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Stimuli\n",
    "\n",
    "Click the **folder icon** on the left and drag `stimuli_with_scrambled.json` into the Files area.\n",
    "\n",
    "Or run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload stimuli_with_scrambled.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_token(token_str):\n",
    "    \"\"\"\n",
    "    Classify GPT-2 BPE token as:\n",
    "    - 'word_start': Begins a new word (space + letter)\n",
    "    - 'punctuation': Punctuation marks  \n",
    "    - 'fragment': Mid-word continuation\n",
    "    \"\"\"\n",
    "    if not token_str:\n",
    "        return 'fragment'\n",
    "    \n",
    "    # Word-initial: space + letter\n",
    "    if token_str[0] == ' ' and len(token_str) > 1 and token_str[1].isalpha():\n",
    "        return 'word_start'\n",
    "    \n",
    "    # Punctuation\n",
    "    if token_str.strip() in '.,!?;:\"\\'\\-':\n",
    "        return 'punctuation'\n",
    "    \n",
    "    # Everything else is a fragment\n",
    "    return 'fragment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"Loading GPT-2...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "print(\"✓ Model loaded\\n\")\n",
    "\n",
    "print(\"Loading stimuli...\")\n",
    "with open('stimuli_with_scrambled.json') as f:\n",
    "    stimuli = json.load(f)\n",
    "print(f\"✓ Loaded {len(stimuli)} stimulus sets\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Sanity Test - Verify Classification Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SANITY TEST: Token Classification\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "test_cases = [\n",
    "    (' cat', 'word_start', 'Space + letter → word_start'),\n",
    "    (' dog', 'word_start', 'Space + letter → word_start'),\n",
    "    (',', 'punctuation', 'Comma → punctuation'),\n",
    "    ('.', 'punctuation', 'Period → punctuation'),\n",
    "    ('ing', 'fragment', 'No space → fragment'),\n",
    "    ('ed', 'fragment', 'No space → fragment'),\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for token, expected, desc in test_cases:\n",
    "    result = classify_token(token)\n",
    "    status = \"✓\" if result == expected else \"✗ FAIL\"\n",
    "    if result != expected:\n",
    "        all_passed = False\n",
    "    print(f\"{status}  {repr(token):12s} → {result:12s}  ({desc})\")\n",
    "\n",
    "print()\n",
    "if all_passed:\n",
    "    print(\"✓ All sanity tests passed!\")\n",
    "else:\n",
    "    print(\"✗ Some tests FAILED - check classification logic\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_position(model, tokenizer, text, target_position, k=100):\n",
    "    \"\"\"\n",
    "    Analyze token predictions at a specific word position.\n",
    "    Returns probability mass on word_start, punctuation, and fragment classes.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    context = ' '.join(words[:target_position+1])\n",
    "    inputs = tokenizer(context, return_tensors='pt')\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        next_token_logits = outputs.logits[0, -1, :]\n",
    "        probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        top_k_probs, top_k_ids = torch.topk(probs, k)\n",
    "    \n",
    "    # Classify and accumulate\n",
    "    class_probs = {'word_start': 0.0, 'punctuation': 0.0, 'fragment': 0.0}\n",
    "    candidates = []\n",
    "    \n",
    "    for prob, token_id in zip(top_k_probs, top_k_ids):\n",
    "        token_str = tokenizer.decode([token_id])\n",
    "        token_class = classify_token(token_str)\n",
    "        \n",
    "        class_probs[token_class] += prob.item()\n",
    "        candidates.append({\n",
    "            'token': repr(token_str),\n",
    "            'class': token_class,\n",
    "            'prob': prob.item()\n",
    "        })\n",
    "    \n",
    "    # Normalize to percentage\n",
    "    total = sum(class_probs.values())\n",
    "    class_pcts = {k: (v/total)*100 if total > 0 else 0.0 for k, v in class_probs.items()}\n",
    "    \n",
    "    return {\n",
    "        'class_percentages': class_pcts,\n",
    "        'top_10': candidates[:10]\n",
    "    }\n",
    "\n",
    "def find_cue_position(text, cue_word):\n",
    "    \"\"\"Find first occurrence of cue word.\"\"\"\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        if word.lower().strip('.,!?;:') == cue_word.lower():\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Analysis on First 5 Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"WORD-CLASS CONSTRAINT AUDIT\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"Analysis: Predictions after 'the' (determiner)\")\n",
    "print()\n",
    "\n",
    "results_by_condition = {\n",
    "    'sentence': [],\n",
    "    'jabberwocky_matched': [],\n",
    "    'scrambled_jabberwocky': []\n",
    "}\n",
    "\n",
    "for stim_idx in range(min(5, len(stimuli))):\n",
    "    stim = stimuli[stim_idx]\n",
    "    \n",
    "    print(f\"\\nSTIMULUS {stim_idx + 1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for condition in ['sentence', 'jabberwocky_matched', 'scrambled_jabberwocky']:\n",
    "        text = stim[condition]\n",
    "        cue_pos = find_cue_position(text, 'the')\n",
    "        \n",
    "        if cue_pos is None:\n",
    "            print(f\"\\n{condition:25s}: (No 'the' found)\")\n",
    "            continue\n",
    "        \n",
    "        result = analyze_position(model, tokenizer, text, cue_pos, k=100)\n",
    "        \n",
    "        # Store for summary\n",
    "        results_by_condition[condition].append(\n",
    "            result['class_percentages']['word_start']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{condition.upper()}:\")\n",
    "        print(f\"  Text: {text[:60]}...\")\n",
    "        print(f\"  Class distribution:\")\n",
    "        print(f\"    Word-start:    {result['class_percentages']['word_start']:5.1f}%\")\n",
    "        print(f\"    Punctuation:   {result['class_percentages']['punctuation']:5.1f}%\")\n",
    "        print(f\"    Fragments:     {result['class_percentages']['fragment']:5.1f}%\")\n",
    "        print(f\"  Top-10 predictions:\")\n",
    "        for cand in result['top_10']:\n",
    "            print(f\"    {cand['token']:20s} [{cand['class']:12s}] {cand['prob']*100:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: % Probability on Word-Initial Tokens (after 'the')\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "summary_stats = {}\n",
    "for condition in ['sentence', 'jabberwocky_matched', 'scrambled_jabberwocky']:\n",
    "    pcts = results_by_condition[condition]\n",
    "    if pcts:\n",
    "        mean_pct = np.mean(pcts)\n",
    "        std_pct = np.std(pcts)\n",
    "        summary_stats[condition] = {'mean': mean_pct, 'std': std_pct, 'n': len(pcts)}\n",
    "        print(f\"{condition:25s}: {mean_pct:5.1f}% ± {std_pct:4.1f}%  (n={len(pcts)})\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "jab_mean = summary_stats.get('jabberwocky_matched', {}).get('mean', 0)\n",
    "scr_mean = summary_stats.get('scrambled_jabberwocky', {}).get('mean', 0)\n",
    "delta = jab_mean - scr_mean\n",
    "\n",
    "print(f\"Δ (Jabberwocky - Scrambled): {delta:+.1f}%\")\n",
    "print()\n",
    "\n",
    "if delta > 5:\n",
    "    print(\"✓ STRUCTURE CONSTRAINS DISTRIBUTION\")\n",
    "    print()\n",
    "    print(\"  Jabberwocky shows higher word-start probability, demonstrating that\")\n",
    "    print(\"  syntactic structure (even with nonsense words) narrows the continuation\")\n",
    "    print(\"  space toward word-initial positions.\")\n",
    "    print()\n",
    "    print(\"  This confirms category-level constraint beyond lexical co-occurrence.\")\n",
    "else:\n",
    "    print(\"✗ Weak effect: Similar word-start probabilities across conditions.\")\n",
    "    print(\"  Structure may not be strongly constraining the distribution.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Full Analysis (All 30 Stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running full analysis on all stimuli...\")\n",
    "print(\"(This may take 2-3 minutes)\\n\")\n",
    "\n",
    "full_results = {\n",
    "    'sentence': [],\n",
    "    'jabberwocky_matched': [],\n",
    "    'scrambled_jabberwocky': []\n",
    "}\n",
    "\n",
    "for stim_idx, stim in enumerate(stimuli):\n",
    "    if (stim_idx + 1) % 5 == 0:\n",
    "        print(f\"  Processing stimulus {stim_idx + 1}/{len(stimuli)}...\")\n",
    "    \n",
    "    for condition in ['sentence', 'jabberwocky_matched', 'scrambled_jabberwocky']:\n",
    "        text = stim[condition]\n",
    "        cue_pos = find_cue_position(text, 'the')\n",
    "        \n",
    "        if cue_pos is not None:\n",
    "            result = analyze_position(model, tokenizer, text, cue_pos, k=100)\n",
    "            full_results[condition].append({\n",
    "                'stimulus_idx': stim_idx,\n",
    "                'word_start_pct': result['class_percentages']['word_start'],\n",
    "                'punctuation_pct': result['class_percentages']['punctuation'],\n",
    "                'fragment_pct': result['class_percentages']['fragment']\n",
    "            })\n",
    "\n",
    "print(\"\\n✓ Analysis complete!\\n\")\n",
    "\n",
    "# Final summary\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY (All Stimuli)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "for condition in ['sentence', 'jabberwocky_matched', 'scrambled_jabberwocky']:\n",
    "    pcts = [r['word_start_pct'] for r in full_results[condition]]\n",
    "    if pcts:\n",
    "        print(f\"{condition:25s}: {np.mean(pcts):5.1f}% ± {np.std(pcts):4.1f}%  (n={len(pcts)})\")\n",
    "\n",
    "print()\n",
    "jab_full = [r['word_start_pct'] for r in full_results['jabberwocky_matched']]\n",
    "scr_full = [r['word_start_pct'] for r in full_results['scrambled_jabberwocky']]\n",
    "\n",
    "if jab_full and scr_full:\n",
    "    delta_full = np.mean(jab_full) - np.mean(scr_full)\n",
    "    print(f\"Δ (Jabberwocky - Scrambled): {delta_full:+.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats\n",
    "    t_stat, p_value = stats.ttest_ind(jab_full, scr_full)\n",
    "    print(f\"t-test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"\\n✓ Statistically significant difference (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"\\n✗ Not statistically significant (p >= 0.05)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "output = {\n",
    "    'analysis_type': 'word_class_constraint',\n",
    "    'model': 'gpt2',\n",
    "    'cue_word': 'the',\n",
    "    'top_k': 100,\n",
    "    'results': full_results,\n",
    "    'summary': {\n",
    "        condition: {\n",
    "            'mean_word_start_pct': float(np.mean([r['word_start_pct'] for r in full_results[condition]])),\n",
    "            'std_word_start_pct': float(np.std([r['word_start_pct'] for r in full_results[condition]])),\n",
    "            'n': len(full_results[condition])\n",
    "        }\n",
    "        for condition in ['sentence', 'jabberwocky_matched', 'scrambled_jabberwocky']\n",
    "        if full_results[condition]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('word_class_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"✓ Results saved to word_class_results.json\")\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('word_class_results.json')\n",
    "print(\"✓ Download started!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
