{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modal Diagnostics with Dynamic Cue Location\n",
    "\n",
    "This notebook investigates why SENTENCE ≈ JABBERWOCKY for modals while other cue families show SENTENCE > JABBERWOCKY.\n",
    "\n",
    "**Key Fix:** This version uses **DYNAMIC cue location** - it finds the cue word's actual position in each condition string, rather than assuming a fixed position. This makes scrambled baselines valid.\n",
    "\n",
    "## Outputs\n",
    "1. `modal_cue_alignment_log.txt` - Cue location statistics\n",
    "2. `modal_next_token_diagnostics.md` - Top-30 predictions for sampled items\n",
    "3. `modal_mass_decomposition.csv` - Mass breakdown by bucket\n",
    "4. `modal_summary_altTargets.csv` - Summary with VerbOnly and VPStart\n",
    "5. `modal_contrasts_altTargets.csv` - Statistical contrasts\n",
    "6. `figure_modals_altTargets.png` - Paper-ready figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/morphosyntax_modal_diagnostics'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers torch pandas numpy matplotlib scipy tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = 'gpt2'  # Change to 'gpt2-medium', 'gpt2-large', etc. if desired\n",
    "\n",
    "MODALS_LIST = {'can', 'will', 'could', 'would', 'should', 'must', 'may', 'might'}\n",
    "\n",
    "# Target class definitions\n",
    "VERB_SET = {\n",
    "    'be', 'have', 'do', 'say', 'go', 'get', 'make', 'know', 'think', 'take',\n",
    "    'see', 'come', 'want', 'use', 'find', 'give', 'tell', 'work', 'call', 'try',\n",
    "    'ask', 'need', 'feel', 'become', 'leave', 'put', 'mean', 'keep', 'let', 'begin',\n",
    "    'seem', 'help', 'show', 'hear', 'play', 'run', 'move', 'live', 'believe',\n",
    "    'bring', 'happen', 'write', 'sit', 'stand', 'lose', 'pay', 'meet', 'continue',\n",
    "    'set', 'learn', 'change', 'lead', 'understand', 'watch', 'follow', 'stop', 'create', 'speak',\n",
    "    'read', 'allow', 'add', 'spend', 'grow', 'open', 'walk', 'win', 'teach', 'offer',\n",
    "    'remember', 'love', 'consider', 'appear', 'buy', 'serve', 'die', 'send', 'build', 'stay',\n",
    "    'fall', 'cut', 'reach', 'kill', 'raise', 'pass', 'sell', 'decide', 'return', 'explain',\n",
    "    'hope', 'develop', 'carry', 'break', 'receive', 'agree', 'support', 'hit', 'produce', 'eat',\n",
    "    'study', 'research', 'investigate', 'examine', 'analyze', 'explore',\n",
    "    'paint', 'draw', 'design', 'construct', 'perform', 'practice',\n",
    "    'publish', 'edit', 'revise', 'prepare', 'cook', 'repair', 'fix',\n",
    "    'solve', 'calculate', 'improve', 'enhance', 'test', 'validate',\n",
    "    'organize', 'arrange', 'defend', 'protect', 'film', 'record',\n",
    "    'sail', 'navigate', 'discuss', 'debate', 'assemble', 'combine',\n",
    "    'plan', 'schedule', 'finish', 'complete', 'start', 'end',\n",
    "}\n",
    "\n",
    "# BE/HAVE/DO auxiliary forms\n",
    "BEHAVE_SET = {\n",
    "    'be', 'been', 'being', 'am', 'is', 'are', 'was', 'were',\n",
    "    'have', 'has', 'had', 'having',\n",
    "    'do', 'does', 'did', 'done', 'doing',\n",
    "}\n",
    "\n",
    "# Negation tokens\n",
    "NEG_SET = {'not', \"n't\", \"nt\"}\n",
    "\n",
    "# Common adverbs that might follow modals\n",
    "ADV_SET = {\n",
    "    'also', 'always', 'never', 'ever', 'just', 'still', 'only', 'even',\n",
    "    'already', 'often', 'soon', 'now', 'then', 'perhaps', 'probably',\n",
    "    'certainly', 'definitely', 'possibly', 'actually', 'really', 'simply',\n",
    "    'easily', 'quickly', 'slowly', 'well', 'better', 'best',\n",
    "}\n",
    "\n",
    "CONDITIONS = ['sentence', 'jabberwocky', 'full_scrambled', 'content_scrambled', 'function_scrambled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cue_position(condition_text, cue_word, expected_occurrence=1):\n",
    "    \"\"\"\n",
    "    DYNAMICALLY locate the cue word in a condition string.\n",
    "    \n",
    "    This is the KEY FIX - instead of assuming cue is at a fixed position,\n",
    "    we find where it actually is in each condition.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (cue_index, status, message)\n",
    "    \"\"\"\n",
    "    words = condition_text.lower().split()\n",
    "    cue_lower = cue_word.lower()\n",
    "    \n",
    "    # Find all indices where word matches cue\n",
    "    matches = []\n",
    "    for i, w in enumerate(words):\n",
    "        w_clean = w.strip('.,!?;:\"\\'-()\"\\'[]{}«»')\n",
    "        if w_clean == cue_lower:\n",
    "            matches.append(i)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        return None, 'missing', f\"Cue '{cue_word}' not found in text\"\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0], 'ok', f\"Cue found at position {matches[0]}\"\n",
    "    else:\n",
    "        return matches[0], 'ambiguous', f\"Cue found {len(matches)} times at {matches}, using first\"\n",
    "\n",
    "\n",
    "def is_word_start_token(tokenizer, token_id):\n",
    "    \"\"\"Check if token is word-start (space-prefixed).\"\"\"\n",
    "    token_str = tokenizer.decode([token_id])\n",
    "    if token_str in ['<|endoftext|>', '<unk>', '<pad>', '']:\n",
    "        return False, None\n",
    "    if token_str.startswith(' ') or token_str.startswith('\\n'):\n",
    "        word = token_str.strip().lower().strip('.,!?;:\"\\'-()')\n",
    "        return True, word\n",
    "    return False, None\n",
    "\n",
    "\n",
    "def contains_negation(token_str):\n",
    "    \"\"\"Check if token contains negation.\"\"\"\n",
    "    token_lower = token_str.lower().strip()\n",
    "    if token_lower in NEG_SET:\n",
    "        return True\n",
    "    if \"n't\" in token_lower or \"nt\" in token_lower:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def classify_token(word, token_str):\n",
    "    \"\"\"Classify a token into buckets.\"\"\"\n",
    "    if word is None:\n",
    "        return 'OTHER'\n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    if contains_negation(token_str):\n",
    "        return 'NEG'\n",
    "    if word_lower in BEHAVE_SET:\n",
    "        return 'BEHAVE'\n",
    "    if word_lower in VERB_SET and word_lower not in BEHAVE_SET:\n",
    "        return 'VERB'\n",
    "    if word_lower in ADV_SET:\n",
    "        return 'ADV'\n",
    "    return 'OTHER'\n",
    "\n",
    "\n",
    "def get_context_at_cue(text, cue_position):\n",
    "    \"\"\"Get context up to and including cue.\"\"\"\n",
    "    words = text.split()\n",
    "    return ' '.join(words[:cue_position + 1])\n",
    "\n",
    "\n",
    "def compute_mass_decomposition(probs, tokenizer, top_k=1000):\n",
    "    \"\"\"Compute probability mass in each bucket.\"\"\"\n",
    "    top_k_probs, top_k_ids = torch.topk(probs, min(top_k, len(probs)))\n",
    "    \n",
    "    mass = {'VERB': 0.0, 'BEHAVE': 0.0, 'NEG': 0.0, 'ADV': 0.0, 'OTHER': 0.0}\n",
    "    \n",
    "    for prob, token_id in zip(top_k_probs, top_k_ids):\n",
    "        is_start, word = is_word_start_token(tokenizer, token_id.item())\n",
    "        if not is_start:\n",
    "            continue\n",
    "        token_str = tokenizer.decode([token_id.item()])\n",
    "        bucket = classify_token(word, token_str)\n",
    "        mass[bucket] += prob.item()\n",
    "    \n",
    "    return mass\n",
    "\n",
    "\n",
    "def get_top_predictions(probs, tokenizer, top_k=30):\n",
    "    \"\"\"Get top-k predictions with classification.\"\"\"\n",
    "    top_k_probs, top_k_ids = torch.topk(probs, min(top_k, len(probs)))\n",
    "    \n",
    "    predictions = []\n",
    "    for prob, token_id in zip(top_k_probs, top_k_ids):\n",
    "        token_str = tokenizer.decode([token_id.item()])\n",
    "        is_start, word = is_word_start_token(tokenizer, token_id.item())\n",
    "        \n",
    "        if is_start:\n",
    "            bucket = classify_token(word, token_str)\n",
    "            in_verb_only = word.lower() in VERB_SET if word else False\n",
    "        else:\n",
    "            bucket = 'SUBWORD'\n",
    "            in_verb_only = False\n",
    "        \n",
    "        predictions.append({\n",
    "            'token': token_str,\n",
    "            'prob': prob.item(),\n",
    "            'word': word,\n",
    "            'bucket': bucket,\n",
    "            'in_VerbOnly': in_verb_only,\n",
    "        })\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload stimuli_locked.json\n",
    "from google.colab import files\n",
    "print(\"Please upload stimuli_locked.json:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load stimuli\n",
    "stimuli_file = list(uploaded.keys())[0]\n",
    "with open(stimuli_file, 'r') as f:\n",
    "    all_stimuli = json.load(f)\n",
    "\n",
    "# Filter to modals only\n",
    "modal_stimuli = [s for s in all_stimuli if s['cue_family'] == 'modals']\n",
    "print(f\"\\nLoaded {len(modal_stimuli)} modal stimuli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Cue Alignment Check with Dynamic Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"STEP 0: Cue Alignment Check (Dynamic Location)\")\nprint(\"=\" * 70)\n\nalignment_log = [\n    \"MODAL CUE ALIGNMENT LOG (DYNAMIC LOCATION)\",\n    f\"Generated: {datetime.now().isoformat()}\",\n    \"=\" * 60,\n    \"\",\n    \"This version DYNAMICALLY locates the cue in each condition,\",\n    \"so scrambled conditions are now analyzed correctly.\",\n    \"\"\n]\n\ncue_location_stats = {cond: {'ok': 0, 'missing': 0, 'ambiguous': 0, 'positions': []} for cond in CONDITIONS}\nissues_found = 0\n\nfor stim in modal_stimuli:\n    item_id = stim['set_id']\n    cue_word = stim['cue_word'].lower()\n    \n    if cue_word not in MODALS_LIST:\n        alignment_log.append(f\"[FAIL] Item {item_id}: cue_word '{cue_word}' not in MODALS_LIST\")\n        issues_found += 1\n        continue\n    \n    for cond in CONDITIONS:\n        text = stim[cond]\n        cue_pos, status, message = find_cue_position(text, cue_word)\n        \n        cue_location_stats[cond][status] += 1\n        if cue_pos is not None:\n            cue_location_stats[cond]['positions'].append(cue_pos)\n        \n        if status == 'missing':\n            alignment_log.append(f\"[FAIL] Item {item_id} {cond}: {message}\")\n            issues_found += 1\n        elif status == 'ambiguous':\n            alignment_log.append(f\"[WARN] Item {item_id} {cond}: {message}\")\n\n# Summary\nalignment_log.extend([\"\", \"=\" * 60, \"DYNAMIC CUE LOCATION SUMMARY\", \"=\" * 60, \"\"])\n\nprint(\"\\nCue location summary by condition:\")\nfor cond in CONDITIONS:\n    cue_stats = cue_location_stats[cond]  # Renamed to avoid shadowing scipy.stats\n    total = cue_stats['ok'] + cue_stats['missing'] + cue_stats['ambiguous']\n    valid = cue_stats['ok'] + cue_stats['ambiguous']\n    positions = cue_stats['positions']\n    \n    if positions:\n        pos_min, pos_max = min(positions), max(positions)\n        pos_mean = sum(positions) / len(positions)\n        pos_range = f\"range [{pos_min}-{pos_max}], mean={pos_mean:.1f}\"\n    else:\n        pos_range = \"no valid positions\"\n    \n    print(f\"  {cond}: {valid}/{total} valid, positions {pos_range}\")\n    \n    alignment_log.extend([\n        f\"{cond.upper()}:\",\n        f\"  Valid items: {valid}/{total} ({100*valid/total:.1f}%)\",\n        f\"  - ok: {cue_stats['ok']}, missing: {cue_stats['missing']}, ambiguous: {cue_stats['ambiguous']}\",\n        f\"  Cue positions: {pos_range}\",\n        \"\"\n    ])\n\nalignment_log.extend([f\"Total issues: {issues_found}\", \"Status: \" + (\"PASS\" if issues_found == 0 else \"ISSUES FOUND\")])\n\nwith open(f'{OUTPUT_DIR}/modal_cue_alignment_log.txt', 'w') as f:\n    f.write('\\n'.join(alignment_log))\nprint(f\"\\nSaved: {OUTPUT_DIR}/modal_cue_alignment_log.txt\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Next-Token Diagnostics (10 sampled items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Next-Token Diagnostics (Dynamic Cue Location)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "random.seed(42)\n",
    "sampled_items = random.sample(modal_stimuli, min(10, len(modal_stimuli)))\n",
    "\n",
    "diagnostics_md = [\n",
    "    \"# Modal Next-Token Diagnostics (Dynamic Cue Location)\",\n",
    "    f\"\\nGenerated: {datetime.now().isoformat()}\",\n",
    "    f\"\\nModel: {MODEL_NAME}\",\n",
    "    f\"\\nSampled items: {len(sampled_items)}\",\n",
    "    \"\\n**Note:** Cue position is dynamically located in each condition.\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "for stim in tqdm(sampled_items, desc=\"Sampling diagnostics\"):\n",
    "    item_id = stim['set_id']\n",
    "    cue_word = stim['cue_word']\n",
    "    \n",
    "    diagnostics_md.extend([f\"\\n## Item {item_id} (cue: '{cue_word}')\", \"\"])\n",
    "    \n",
    "    for cond in CONDITIONS:\n",
    "        text = stim[cond]\n",
    "        cue_pos, status, message = find_cue_position(text, cue_word)\n",
    "        \n",
    "        diagnostics_md.append(f\"### {cond.upper()}\")\n",
    "        \n",
    "        if cue_pos is None:\n",
    "            diagnostics_md.extend([f\"**SKIPPED:** {message}\", \"\"])\n",
    "            continue\n",
    "        \n",
    "        context = get_context_at_cue(text, cue_pos)\n",
    "        diagnostics_md.extend([\n",
    "            f\"**Cue position:** {cue_pos} ({status})\",\n",
    "            f\"**Context:** `{context}`\",\n",
    "            f\"**Full text:** `{text}`\",\n",
    "            \"\"\n",
    "        ])\n",
    "        \n",
    "        # Get predictions\n",
    "        inputs = tokenizer(context, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1).cpu()\n",
    "        \n",
    "        top_preds = get_top_predictions(probs, tokenizer, top_k=30)\n",
    "        \n",
    "        diagnostics_md.extend([\n",
    "            \"| Rank | Token | Prob | Word | Bucket | In VerbOnly |\",\n",
    "            \"|------|-------|------|------|--------|-------------|\"\n",
    "        ])\n",
    "        \n",
    "        for i, p in enumerate(top_preds):\n",
    "            token_display = p['token'].replace('|', '\\\\|').replace('\\n', '\\\\n')\n",
    "            in_vo = \"Y\" if p['in_VerbOnly'] else \"\"\n",
    "            diagnostics_md.append(f\"| {i+1} | `{token_display}` | {p['prob']:.4f} | {p['word']} | {p['bucket']} | {in_vo} |\")\n",
    "        \n",
    "        diagnostics_md.append(\"\")\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/modal_next_token_diagnostics.md', 'w') as f:\n",
    "    f.write('\\n'.join(diagnostics_md))\n",
    "print(f\"Saved: {OUTPUT_DIR}/modal_next_token_diagnostics.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Mass Decomposition for ALL Modal Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STEP 2: Mass Decomposition (Dynamic Cue Location)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "decomposition_results = []\n",
    "skipped_counts = {cond: 0 for cond in CONDITIONS}\n",
    "\n",
    "for stim in tqdm(modal_stimuli, desc=\"Computing mass decomposition\"):\n",
    "    item_id = stim['set_id']\n",
    "    cue_word = stim['cue_word']\n",
    "    \n",
    "    for cond in CONDITIONS:\n",
    "        text = stim[cond]\n",
    "        \n",
    "        # DYNAMICALLY locate cue\n",
    "        cue_pos, status, message = find_cue_position(text, cue_word)\n",
    "        \n",
    "        if cue_pos is None:\n",
    "            skipped_counts[cond] += 1\n",
    "            continue\n",
    "        \n",
    "        context = get_context_at_cue(text, cue_pos)\n",
    "        \n",
    "        inputs = tokenizer(context, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1).cpu()\n",
    "        \n",
    "        mass = compute_mass_decomposition(probs, tokenizer, top_k=1000)\n",
    "        \n",
    "        decomposition_results.append({\n",
    "            'item_id': item_id,\n",
    "            'condition': cond.upper(),\n",
    "            'cue_word': cue_word,\n",
    "            'cue_position': cue_pos,\n",
    "            'mass_VERB': mass['VERB'],\n",
    "            'mass_BEHAVE': mass['BEHAVE'],\n",
    "            'mass_NEG': mass['NEG'],\n",
    "            'mass_ADV': mass['ADV'],\n",
    "            'mass_OTHER': mass['OTHER'],\n",
    "            'mass_VerbOnly': mass['VERB'],\n",
    "            'mass_VPStart': mass['VERB'] + mass['BEHAVE'] + mass['NEG'],\n",
    "        })\n",
    "\n",
    "# Report skipped items\n",
    "print(\"\\nSkipped items (missing cue):\")\n",
    "for cond in CONDITIONS:\n",
    "    if skipped_counts[cond] > 0:\n",
    "        print(f\"  {cond}: {skipped_counts[cond]} items skipped\")\n",
    "\n",
    "decomp_df = pd.DataFrame(decomposition_results)\n",
    "decomp_df.to_csv(f'{OUTPUT_DIR}/modal_mass_decomposition.csv', index=False)\n",
    "print(f\"\\nSaved: {OUTPUT_DIR}/modal_mass_decomposition.csv\")\n",
    "print(f\"Total records: {len(decomp_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Summary and Statistical Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: Alternate Target Definitions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summary table\n",
    "summary_alt = decomp_df.groupby('condition').agg({\n",
    "    'mass_VerbOnly': ['mean', 'std', 'count'],\n",
    "    'mass_VPStart': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "summary_alt.columns = ['condition', 'VerbOnly_mean', 'VerbOnly_std', 'n', 'VPStart_mean', 'VPStart_std']\n",
    "summary_alt['VerbOnly_se'] = summary_alt['VerbOnly_std'] / np.sqrt(summary_alt['n'])\n",
    "summary_alt['VPStart_se'] = summary_alt['VPStart_std'] / np.sqrt(summary_alt['n'])\n",
    "\n",
    "summary_alt.to_csv(f'{OUTPUT_DIR}/modal_summary_altTargets.csv', index=False)\n",
    "print(f\"\\nSaved: {OUTPUT_DIR}/modal_summary_altTargets.csv\")\n",
    "print(\"\\nSummary:\")\n",
    "print(summary_alt[['condition', 'VerbOnly_mean', 'VerbOnly_se', 'VPStart_mean', 'VPStart_se', 'n']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical contrasts\n",
    "contrasts_results = []\n",
    "contrast_pairs = [\n",
    "    ('SENTENCE', 'JABBERWOCKY'),\n",
    "    ('JABBERWOCKY', 'FULL_SCRAMBLED'),\n",
    "    ('JABBERWOCKY', 'CONTENT_SCRAMBLED'),\n",
    "    ('JABBERWOCKY', 'FUNCTION_SCRAMBLED'),\n",
    "]\n",
    "\n",
    "for target_col in ['mass_VerbOnly', 'mass_VPStart']:\n",
    "    target_name = 'VerbOnly' if 'VerbOnly' in target_col else 'VPStart'\n",
    "    \n",
    "    for cond_a, cond_b in contrast_pairs:\n",
    "        df_a = decomp_df[decomp_df['condition'] == cond_a].set_index('item_id')[target_col]\n",
    "        df_b = decomp_df[decomp_df['condition'] == cond_b].set_index('item_id')[target_col]\n",
    "        \n",
    "        common = df_a.index.intersection(df_b.index)\n",
    "        if len(common) == 0:\n",
    "            continue\n",
    "        \n",
    "        x, y = df_a.loc[common].values, df_b.loc[common].values\n",
    "        diff = np.mean(x) - np.mean(y)\n",
    "        t_stat, p_val = stats.ttest_rel(x, y)\n",
    "        d = np.mean(x - y) / np.std(x - y, ddof=1) if np.std(x - y, ddof=1) > 0 else 0\n",
    "        \n",
    "        contrasts_results.append({\n",
    "            'target_def': target_name,\n",
    "            'contrast': f\"{cond_a} - {cond_b}\",\n",
    "            'mean_a': np.mean(x),\n",
    "            'mean_b': np.mean(y),\n",
    "            'diff': diff,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_val,\n",
    "            'cohens_d': d,\n",
    "            'n': len(common),\n",
    "        })\n",
    "\n",
    "contrasts_df = pd.DataFrame(contrasts_results)\n",
    "contrasts_df.to_csv(f'{OUTPUT_DIR}/modal_contrasts_altTargets.csv', index=False)\n",
    "print(f\"\\nSaved: {OUTPUT_DIR}/modal_contrasts_altTargets.csv\")\n",
    "print(\"\\nContrasts:\")\n",
    "print(contrasts_df[['target_def', 'contrast', 'diff', 'p_value', 'cohens_d', 'n']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STEP 4: Generate Figure\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "conditions_order = ['SENTENCE', 'JABBERWOCKY', 'FULL_SCRAMBLED', 'CONTENT_SCRAMBLED', 'FUNCTION_SCRAMBLED']\n",
    "condition_labels = ['Sent', 'Jab', 'Full\\nScram', 'Cont\\nScram', 'Func\\nScram']\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6']\n",
    "\n",
    "for ax_idx, (target_col, title) in enumerate([('mass_VerbOnly', 'VerbOnly (VERB only)'), \n",
    "                                               ('mass_VPStart', 'VPStart (VERB+BE/HAVE+NEG)')]):\n",
    "    ax = axes[ax_idx]\n",
    "    \n",
    "    means = []\n",
    "    ses = []\n",
    "    for cond in conditions_order:\n",
    "        cond_data = decomp_df[decomp_df['condition'] == cond][target_col]\n",
    "        if len(cond_data) > 0:\n",
    "            means.append(cond_data.mean())\n",
    "            ses.append(cond_data.std() / np.sqrt(len(cond_data)))\n",
    "        else:\n",
    "            means.append(0)\n",
    "            ses.append(0)\n",
    "    \n",
    "    x = np.arange(len(conditions_order))\n",
    "    bars = ax.bar(x, means, yerr=ses, capsize=4, color=colors, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "    \n",
    "    ax.set_title(f'Modal Target: {title}', fontweight='bold', fontsize=12)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(condition_labels, fontsize=9)\n",
    "    ax.set_ylabel('Target Class Mass', fontsize=11)\n",
    "    ax.set_ylim(0, max(means) * 1.35 if max(means) > 0 else 1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (m, s) in enumerate(zip(means, ses)):\n",
    "        if m > 0:\n",
    "            ax.text(i, m + s + 0.01, f'{m:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.suptitle(f'Modal Cue Family - Dynamic Cue Location ({MODEL_NAME})', fontweight='bold', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/figure_modals_altTargets.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"\\nSaved: {OUTPUT_DIR}/figure_modals_altTargets.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Key comparison\n",
    "sent_vo = decomp_df[decomp_df['condition'] == 'SENTENCE']['mass_VerbOnly'].mean()\n",
    "jab_vo = decomp_df[decomp_df['condition'] == 'JABBERWOCKY']['mass_VerbOnly'].mean()\n",
    "sent_vp = decomp_df[decomp_df['condition'] == 'SENTENCE']['mass_VPStart'].mean()\n",
    "jab_vp = decomp_df[decomp_df['condition'] == 'JABBERWOCKY']['mass_VPStart'].mean()\n",
    "\n",
    "print(f\"\\nSENTENCE vs JABBERWOCKY comparison:\")\n",
    "print(f\"  VerbOnly:  SENT={sent_vo:.4f}, JAB={jab_vo:.4f}, diff={sent_vo-jab_vo:+.4f}\")\n",
    "print(f\"  VPStart:   SENT={sent_vp:.4f}, JAB={jab_vp:.4f}, diff={sent_vp-jab_vp:+.4f}\")\n",
    "\n",
    "# Get p-values\n",
    "vo_contrast = contrasts_df[(contrasts_df['target_def'] == 'VerbOnly') & (contrasts_df['contrast'] == 'SENTENCE - JABBERWOCKY')]\n",
    "vp_contrast = contrasts_df[(contrasts_df['target_def'] == 'VPStart') & (contrasts_df['contrast'] == 'SENTENCE - JABBERWOCKY')]\n",
    "\n",
    "if len(vo_contrast) > 0:\n",
    "    print(f\"  VerbOnly p-value: {vo_contrast['p_value'].values[0]:.6f}, d={vo_contrast['cohens_d'].values[0]:.2f}\")\n",
    "if len(vp_contrast) > 0:\n",
    "    print(f\"  VPStart p-value:  {vp_contrast['p_value'].values[0]:.6f}, d={vp_contrast['cohens_d'].values[0]:.2f}\")\n",
    "\n",
    "# Scrambled baselines (NOW VALID with dynamic cue location)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SCRAMBLED BASELINES (Now Valid with Dynamic Cue Location)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for contrast_name in ['JABBERWOCKY - FULL_SCRAMBLED', 'JABBERWOCKY - FUNCTION_SCRAMBLED']:\n",
    "    print(f\"\\n{contrast_name}:\")\n",
    "    for target in ['VerbOnly', 'VPStart']:\n",
    "        row = contrasts_df[(contrasts_df['target_def'] == target) & (contrasts_df['contrast'] == contrast_name)]\n",
    "        if len(row) > 0:\n",
    "            r = row.iloc[0]\n",
    "            sig = \"***\" if r['p_value'] < 0.001 else \"**\" if r['p_value'] < 0.01 else \"*\" if r['p_value'] < 0.05 else \"n.s.\"\n",
    "            print(f\"  {target}: diff={r['diff']:+.4f}, p={r['p_value']:.4f} {sig}, d={r['cohens_d']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETATION (with Dynamic Cue Location)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNote: This analysis uses DYNAMIC cue location for all conditions,\")\n",
    "print(\"so scrambled baselines now correctly measure 'prediction after the\")\n",
    "print(\"modal cue with disrupted structure' - not arbitrary position 2.\")\n",
    "print()\n",
    "\n",
    "if sent_vp > jab_vp and (sent_vo - jab_vo) < (sent_vp - jab_vp):\n",
    "    print(\"-> The VerbOnly target definition appears to be an ARTIFACT.\")\n",
    "    print(\"   When BE/HAVE/NEG are included (VPStart), SENTENCE > JABBERWOCKY as expected.\")\n",
    "    print(\"   Real sentences use more auxiliary/negation continuations after modals.\")\n",
    "else:\n",
    "    print(\"-> Modals appear to be genuinely CUE-DRIVEN.\")\n",
    "    print(\"   Even with expanded target definition, SENTENCE ~ JABBERWOCKY.\")\n",
    "    print(\"   The modal cue alone saturates morphosyntactic constraint.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OUTPUT FILES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"1. {OUTPUT_DIR}/modal_cue_alignment_log.txt\")\n",
    "print(f\"2. {OUTPUT_DIR}/modal_next_token_diagnostics.md\")\n",
    "print(f\"3. {OUTPUT_DIR}/modal_mass_decomposition.csv\")\n",
    "print(f\"4. {OUTPUT_DIR}/modal_summary_altTargets.csv\")\n",
    "print(f\"5. {OUTPUT_DIR}/modal_contrasts_altTargets.csv\")\n",
    "print(f\"6. {OUTPUT_DIR}/figure_modals_altTargets.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}