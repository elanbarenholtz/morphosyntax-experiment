{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphosyntax Constraint Audit: Content-Scrambled Control\n",
    "\n",
    "**Goal**: Test whether content sequencing matters when function skeleton is preserved.\n",
    "\n",
    "**Conditions**:\n",
    "1. **SENTENCE**: Real English (\"the scientist decided to study...\")\n",
    "2. **JABBERWOCKY**: Nonsense words, preserved structure (\"the prell decided to cleb...\")\n",
    "3. **CONTENT_SCRAMBLED**: Same function skeleton, shuffled content (\"the cleb decided to braz...\")\n",
    "\n",
    "**Key comparison**: JABBERWOCKY vs CONTENT_SCRAMBLED (matched n=30/30 \"to\" instances)\n",
    "\n",
    "**Prediction**:\n",
    "- If **sequencing matters**: JABBERWOCKY > CONTENT_SCRAMBLED\n",
    "- If **only skeleton matters**: JABBERWOCKY ≈ CONTENT_SCRAMBLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload stimuli_content_scrambled.json before running!\n",
    "import json\n",
    "import torch\n",
    "import spacy\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from scipy import stats\n",
    "\n",
    "# Install spaCy model if needed\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2\n",
    "print(\"Loading GPT-2...\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "print(\"✓ GPT-2 loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stimuli\n",
    "with open('stimuli_content_scrambled.json', 'r') as f:\n",
    "    stimuli = json.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(stimuli)} stimulus sets\")\n",
    "print(f\"\\nExample (Set 1):\")\n",
    "print(f\"  Sentence:     {stimuli[0]['sentence']}\")\n",
    "print(f\"  Jabberwocky:  {stimuli[0]['jabberwocky_matched']}\")\n",
    "print(f\"  Content-scrambled: {stimuli[0]['content_scrambled_jabberwocky']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERB lexicon (same as refined audit)\n",
    "VERB_SET = {\n",
    "    # Common verbs\n",
    "    'be', 'have', 'do', 'say', 'go', 'get', 'make', 'know', 'think', 'take',\n",
    "    'see', 'come', 'want', 'use', 'find', 'give', 'tell', 'work', 'call', 'try',\n",
    "    'ask', 'need', 'feel', 'become', 'leave', 'put', 'mean', 'keep', 'let', 'begin',\n",
    "    'seem', 'help', 'show', 'hear', 'play', 'run', 'move', 'like', 'live', 'believe',\n",
    "    'bring', 'happen', 'write', 'sit', 'stand', 'lose', 'pay', 'meet', 'include', 'continue',\n",
    "    'set', 'learn', 'change', 'lead', 'understand', 'watch', 'follow', 'stop', 'create', 'speak',\n",
    "    'read', 'allow', 'add', 'spend', 'grow', 'open', 'walk', 'win', 'teach', 'offer',\n",
    "    'remember', 'love', 'consider', 'appear', 'buy', 'serve', 'die', 'send', 'build', 'stay',\n",
    "    'fall', 'cut', 'reach', 'kill', 'raise', 'pass', 'sell', 'decide', 'return', 'explain',\n",
    "    'hope', 'develop', 'carry', 'break', 'receive', 'agree', 'support', 'hit', 'produce', 'eat',\n",
    "    # Additional verbs from templates\n",
    "    'study', 'research', 'investigate', 'examine', 'analyze', 'explore',\n",
    "    'paint', 'draw', 'create', 'design', 'build', 'construct',\n",
    "    'play', 'perform', 'practice', 'rehearse',\n",
    "    'publish', 'write', 'edit', 'revise',\n",
    "    'prepare', 'cook', 'bake',\n",
    "    'repair', 'fix', 'mend',\n",
    "    'solve', 'calculate', 'compute',\n",
    "    'improve', 'enhance', 'upgrade',\n",
    "    'debug', 'test', 'validate',\n",
    "    'organize', 'arrange', 'sort',\n",
    "    'defend', 'protect', 'guard',\n",
    "    'film', 'record', 'capture',\n",
    "    'sail', 'navigate', 'steer',\n",
    "    'discuss', 'debate', 'argue',\n",
    "    'assemble', 'combine', 'join',\n",
    "    'refine', 'polish', 'perfect',\n",
    "    'plan', 'schedule', 'arrange',\n",
    "    'finish', 'complete', 'conclude',\n",
    "}\n",
    "\n",
    "print(f\"✓ VERB set: {len(VERB_SET)} verbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_mass_after_to(text, model, tokenizer, nlp, verb_set):\n",
    "    \"\"\"\n",
    "    Compute VERB probability mass after infinitival 'to'.\n",
    "    \n",
    "    Returns:\n",
    "        to_instances: list of dicts with verb_mass for each 'to' occurrence\n",
    "    \"\"\"\n",
    "    # Parse with spaCy\n",
    "    doc = nlp(text)\n",
    "    words = text.split()\n",
    "    \n",
    "    to_instances = []\n",
    "    \n",
    "    # Find all \"to\" tokens\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() != 'to':\n",
    "            continue\n",
    "        \n",
    "        # Build context up to and including \"to\"\n",
    "        context = ' '.join(words[:i+1])\n",
    "        \n",
    "        # Tokenize context\n",
    "        inputs = tokenizer(context, return_tensors='pt')\n",
    "        \n",
    "        # Get next-token distribution\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get top-100 predictions\n",
    "        top_k_probs, top_k_ids = torch.topk(probs, 100)\n",
    "        \n",
    "        # Compute VERB mass\n",
    "        verb_mass = 0.0\n",
    "        \n",
    "        for prob, token_id in zip(top_k_probs, top_k_ids):\n",
    "            token_str = tokenizer.decode([token_id]).strip().lower()\n",
    "            \n",
    "            # Check if word-start token (starts with space in GPT-2)\n",
    "            raw_token = tokenizer.decode([token_id])\n",
    "            if not raw_token.startswith(' '):\n",
    "                continue\n",
    "            \n",
    "            # Check if VERB\n",
    "            if token_str in verb_set:\n",
    "                verb_mass += prob.item()\n",
    "        \n",
    "        to_instances.append({\n",
    "            'to_word_index': i,\n",
    "            'context': context,\n",
    "            'verb_mass': verb_mass,\n",
    "            'num_context_tokens': len(inputs['input_ids'][0])\n",
    "        })\n",
    "    \n",
    "    return to_instances\n",
    "\n",
    "print(\"✓ Analysis function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run audit on all 3 conditions\n",
    "results = []\n",
    "\n",
    "conditions = [\n",
    "    ('sentence', 'SENTENCE'),\n",
    "    ('jabberwocky_matched', 'JABBERWOCKY'),\n",
    "    ('content_scrambled_jabberwocky', 'CONTENT_SCRAMBLED')\n",
    "]\n",
    "\n",
    "print(\"Running morphosyntax audit...\\n\")\n",
    "\n",
    "for set_idx, stim_set in enumerate(stimuli):\n",
    "    set_id = stim_set['set_id']\n",
    "    \n",
    "    if (set_idx + 1) % 5 == 0:\n",
    "        print(f\"Processing set {set_idx + 1}/30...\")\n",
    "    \n",
    "    for cond_key, cond_name in conditions:\n",
    "        text = stim_set[cond_key]\n",
    "        \n",
    "        # Get VERB mass for all \"to\" instances\n",
    "        to_instances = get_verb_mass_after_to(text, model, tokenizer, nlp, VERB_SET)\n",
    "        \n",
    "        # Record each instance\n",
    "        for instance in to_instances:\n",
    "            results.append({\n",
    "                'set_id': set_id,\n",
    "                'condition': cond_name,\n",
    "                'text': text,\n",
    "                'to_word_index': instance['to_word_index'],\n",
    "                'context': instance['context'],\n",
    "                'verb_mass': instance['verb_mass'],\n",
    "                'num_context_tokens': instance['num_context_tokens']\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Processed {len(stimuli)} stimulus sets\")\n",
    "print(f\"✓ Total instances: {len(results)}\")\n",
    "\n",
    "# Count per condition\n",
    "for _, cond_name in conditions:\n",
    "    n = sum(1 for r in results if r['condition'] == cond_name)\n",
    "    print(f\"  {cond_name}: n={n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_file = 'morphosyntax_audit_content_scrambled_results.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate per sentence set\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group by set_id and condition\n",
    "aggregated = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for r in results:\n",
    "    aggregated[r['set_id']][r['condition']].append(r['verb_mass'])\n",
    "\n",
    "# Compute means\n",
    "summary_data = []\n",
    "\n",
    "for set_id in sorted(aggregated.keys()):\n",
    "    row = {'set_id': set_id}\n",
    "    \n",
    "    for _, cond_name in conditions:\n",
    "        if cond_name in aggregated[set_id]:\n",
    "            row[cond_name] = np.mean(aggregated[set_id][cond_name])\n",
    "        else:\n",
    "            row[cond_name] = np.nan\n",
    "    \n",
    "    summary_data.append(row)\n",
    "\n",
    "print(\"✓ Aggregated per sentence set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Descriptive statistics\n",
    "for _, cond_name in conditions:\n",
    "    values = df[cond_name].dropna()\n",
    "    print(f\"{cond_name}:\")\n",
    "    print(f\"  n = {len(values)}\")\n",
    "    print(f\"  Mean = {values.mean():.4f}\")\n",
    "    print(f\"  SD = {values.std():.4f}\")\n",
    "    print(f\"  Range = [{values.min():.4f}, {values.max():.4f}]\")\n",
    "    print()\n",
    "\n",
    "# Primary comparison: JABBERWOCKY vs CONTENT_SCRAMBLED (paired)\n",
    "jab_values = df['JABBERWOCKY'].dropna()\n",
    "scram_values = df['CONTENT_SCRAMBLED'].dropna()\n",
    "\n",
    "# Ensure matched pairs\n",
    "matched_df = df[['JABBERWOCKY', 'CONTENT_SCRAMBLED']].dropna()\n",
    "jab_matched = matched_df['JABBERWOCKY'].values\n",
    "scram_matched = matched_df['CONTENT_SCRAMBLED'].values\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(jab_matched, scram_matched)\n",
    "\n",
    "# Cohen's d (paired)\n",
    "diff = jab_matched - scram_matched\n",
    "d = diff.mean() / diff.std()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PRIMARY COMPARISON: JABBERWOCKY vs CONTENT_SCRAMBLED\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"n (matched pairs): {len(jab_matched)}\")\n",
    "print(f\"JABBERWOCKY:      {jab_matched.mean():.4f} ± {jab_matched.std():.4f}\")\n",
    "print(f\"CONTENT_SCRAMBLED: {scram_matched.mean():.4f} ± {scram_matched.std():.4f}\")\n",
    "print()\n",
    "print(f\"Δ (Jab - Scram):  {diff.mean():.4f} ({diff.mean()*100:.1f}% VERB mass)\")\n",
    "print()\n",
    "print(f\"Paired t-test:\")\n",
    "print(f\"  t({len(diff)-1}) = {t_stat:.3f}\")\n",
    "print(f\"  p = {p_value:.4f}\")\n",
    "print(f\"  Cohen's d = {d:.3f}\")\n",
    "print()\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.001:\n",
    "    sig = \"***\"\n",
    "elif p_value < 0.01:\n",
    "    sig = \"**\"\n",
    "elif p_value < 0.05:\n",
    "    sig = \"*\"\n",
    "else:\n",
    "    sig = \"n.s.\"\n",
    "\n",
    "print(f\"Significance: {sig}\")\n",
    "print()\n",
    "\n",
    "if abs(d) < 0.2:\n",
    "    effect = \"negligible\"\n",
    "elif abs(d) < 0.5:\n",
    "    effect = \"small\"\n",
    "elif abs(d) < 0.8:\n",
    "    effect = \"medium\"\n",
    "else:\n",
    "    effect = \"large\"\n",
    "\n",
    "print(f\"Effect size: {effect}\")\n",
    "print()\n",
    "\n",
    "# Interpretation\n",
    "print(\"=\" * 80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "if diff.mean() > 0.02 and p_value < 0.05:\n",
    "    print(\"✓ JABBERWOCKY > CONTENT_SCRAMBLED\")\n",
    "    print(\"  → Content SEQUENCING matters (not just function skeleton)\")\n",
    "    print(\"  → Model is sensitive to linear order of content words\")\n",
    "elif diff.mean() < -0.02 and p_value < 0.05:\n",
    "    print(\"✓ CONTENT_SCRAMBLED > JABBERWOCKY\")\n",
    "    print(\"  → Unexpected! Scrambling IMPROVES predictions?\")\n",
    "    print(\"  → May indicate model exploits accidental regularities\")\n",
    "else:\n",
    "    print(\"✓ JABBERWOCKY ≈ CONTENT_SCRAMBLED\")\n",
    "    print(\"  → Content sequencing does NOT matter\")\n",
    "    print(\"  → Only function-word SKELETON drives predictions\")\n",
    "    print(\"  → Supports purely structural (not sequential) constraint\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paired dot plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot individual pairs\n",
    "for i in range(len(jab_matched)):\n",
    "    ax.plot([1, 2], [jab_matched[i], scram_matched[i]], \n",
    "            'o-', color='gray', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Plot means\n",
    "ax.plot([1, 2], [jab_matched.mean(), scram_matched.mean()], \n",
    "        'o-', color='red', linewidth=3, markersize=12, label='Mean')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlim(0.5, 2.5)\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Jabberwocky', 'Content-Scrambled'])\n",
    "ax.set_ylabel('VERB Probability Mass', fontsize=12)\n",
    "ax.set_title(f'VERB Mass After \"to\": Sequencing Effect\\n'\n",
    "             f'Δ = {diff.mean():.3f}, t({len(diff)-1}) = {t_stat:.2f}, p = {p_value:.4f}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('morphosyntax_content_scrambled_paired_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved plot to: morphosyntax_content_scrambled_paired_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary CSV for paper\n",
    "df.to_csv('morphosyntax_content_scrambled_summary.csv', index=False)\n",
    "print(\"✓ Saved summary to: morphosyntax_content_scrambled_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AUDIT COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDownload these files:\")\n",
    "print(\"  1. morphosyntax_audit_content_scrambled_results.json\")\n",
    "print(\"  2. morphosyntax_content_scrambled_summary.csv\")\n",
    "print(\"  3. morphosyntax_content_scrambled_paired_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
